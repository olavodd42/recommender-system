{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6eba94b",
   "metadata": {},
   "source": [
    "# Cria√ß√£o do Dataset de Treino (Point-in-Time Correct)\n",
    "Neste notebook, montamos o dataset final para treinamento do modelo.\n",
    "Utilizamos o **Feast** para realizar o \"Time-Travel Join\", garantindo que as features associadas a cada transa√ß√£o reflitam o estado dos dados *no momento exato* em que a transa√ß√£o ocorreu, evitando vazamento de dados (data leakage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4c4730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from feast import FeatureStore\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configura√ß√£o\n",
    "REPO_PATH = \"./feature_repo\"\n",
    "DATA_PATH = Path(\"./data\")\n",
    "TRAIN_DATA_PATH = DATA_PATH / \"training_dataset.parquet\"\n",
    "\n",
    "store = FeatureStore(repo_path=REPO_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1997ec45",
   "metadata": {},
   "source": [
    "## 1. Carregamento das Entidades (Transa√ß√µes)\n",
    "Carregamos as transa√ß√µes hist√≥ricas que servir√£o como nossa tabela de entidades.\n",
    "√â fundamental ter a coluna `event_timestamp` para que o Feast saiba \"quando\" buscar as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99c958c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ 1. Carregando hist√≥rico de transa√ß√µes (Positivos)...\n",
      "üì¶ Entidades base carregadas: (300000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"üöÄ 1. Carregando hist√≥rico de transa√ß√µes (Positivos)...\")\n",
    "\n",
    "# Carrega dataset de transa√ß√µes\n",
    "entity_df = pl.read_parquet(DATA_PATH / \"transactions_train.parquet\", columns=['t_dat', 'customer_id', 'article_id'])\n",
    "entity_df = entity_df.with_columns(\n",
    "    pl.col(\"t_dat\").cast(pl.Datetime).alias(\"event_timestamp\")\n",
    ")\n",
    "# Usamos tail() para pegar as transa√ß√µes mais recentes, que alinham com as features\n",
    "entity_df = entity_df.drop(\"t_dat\").tail(300000)\n",
    "\n",
    "print(f\"üì¶ Entidades base carregadas: {entity_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2383c84",
   "metadata": {},
   "source": [
    "## 2. Enriquecimento com Features (Time-Travel Join)\n",
    "Aqui acontece a m√°gica do Feature Store. Solicitamos ao Feast que anexe as features de usu√°rio e item a cada transa√ß√£o.\n",
    "O Feast busca o valor da feature v√°lido no `event_timestamp` da transa√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84e94e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ 2. Invocando Feast para Time-Travel Join...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>avg_spend</th>\n",
       "      <th>purchase_count</th>\n",
       "      <th>popularity_score</th>\n",
       "      <th>avg_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f882d43eb7aab25667917f0ddbc18e994bd31538aa10e2...</td>\n",
       "      <td>0825509004</td>\n",
       "      <td>2020-09-13 00:00:00+00:00</td>\n",
       "      <td>0.029065</td>\n",
       "      <td>49</td>\n",
       "      <td>42</td>\n",
       "      <td>0.012804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ec6d1328d7b8091dddd9b769323c2f55c4f560053d583c...</td>\n",
       "      <td>0901575001</td>\n",
       "      <td>2020-09-13 00:00:00+00:00</td>\n",
       "      <td>0.022451</td>\n",
       "      <td>77</td>\n",
       "      <td>20</td>\n",
       "      <td>0.029129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f1e428069ea3a08ad75c607edd556552c6fc7c3609d121...</td>\n",
       "      <td>0695325020</td>\n",
       "      <td>2020-09-13 00:00:00+00:00</td>\n",
       "      <td>0.024136</td>\n",
       "      <td>7</td>\n",
       "      <td>192</td>\n",
       "      <td>0.023410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f04f22807493a3a0d57dec80326396765ed5b3f80f7f7e...</td>\n",
       "      <td>0872600009</td>\n",
       "      <td>2020-09-13 00:00:00+00:00</td>\n",
       "      <td>0.021280</td>\n",
       "      <td>23</td>\n",
       "      <td>202</td>\n",
       "      <td>0.026835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f18cef960f8901b371958dd413e372ee21d221574d006a...</td>\n",
       "      <td>0870957002</td>\n",
       "      <td>2020-09-13 00:00:00+00:00</td>\n",
       "      <td>0.031993</td>\n",
       "      <td>76</td>\n",
       "      <td>40</td>\n",
       "      <td>0.024872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_id  article_id  \\\n",
       "0  f882d43eb7aab25667917f0ddbc18e994bd31538aa10e2...  0825509004   \n",
       "1  ec6d1328d7b8091dddd9b769323c2f55c4f560053d583c...  0901575001   \n",
       "2  f1e428069ea3a08ad75c607edd556552c6fc7c3609d121...  0695325020   \n",
       "3  f04f22807493a3a0d57dec80326396765ed5b3f80f7f7e...  0872600009   \n",
       "4  f18cef960f8901b371958dd413e372ee21d221574d006a...  0870957002   \n",
       "\n",
       "            event_timestamp  avg_spend  purchase_count  popularity_score  \\\n",
       "0 2020-09-13 00:00:00+00:00   0.029065              49                42   \n",
       "1 2020-09-13 00:00:00+00:00   0.022451              77                20   \n",
       "2 2020-09-13 00:00:00+00:00   0.024136               7               192   \n",
       "3 2020-09-13 00:00:00+00:00   0.021280              23               202   \n",
       "4 2020-09-13 00:00:00+00:00   0.031993              76                40   \n",
       "\n",
       "   avg_price  \n",
       "0   0.012804  \n",
       "1   0.029129  \n",
       "2   0.023410  \n",
       "3   0.026835  \n",
       "4   0.024872  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"‚è≥ 2. Invocando Feast para Time-Travel Join...\")\n",
    "\n",
    "# Cria dataset de treinamento ao obter as user features\n",
    "# avg_spend e purchase_count, e as item features\n",
    "# popularity_score e avg_price\n",
    "training_df = store.get_historical_features(\n",
    "    entity_df=entity_df.to_pandas(),\n",
    "    features=[\n",
    "        \"user_stats:avg_spend\",\n",
    "        \"user_stats:purchase_count\",\n",
    "        \"item_stats:popularity_score\",\n",
    "        \"item_stats:avg_price\"\n",
    "    ]\n",
    ").to_df()\n",
    "\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7816f8b2",
   "metadata": {},
   "source": [
    "## 3. Tratamento de Valores Nulos\n",
    "Features podem vir nulas se, no momento da transa√ß√£o, o usu√°rio ou item n√£o tinha hist√≥rico (Cold Start). Preenchemos com 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6d08e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ 3. Limpeza e Preenchimento de Nulos...\n"
     ]
    }
   ],
   "source": [
    "print(\"üßπ 3. Limpeza e Preenchimento de Nulos...\")\n",
    "\n",
    "# Feature Stores geram Nulos se o usu√°rio era novo na √©poca.\n",
    "training_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d321a9b5",
   "metadata": {},
   "source": [
    "## 4. Pr√©-processamento Final e Salvamento\n",
    "Modelos de Deep Learning (como Two-Tower) precisam de IDs num√©ricos cont√≠nuos para suas camadas de Embedding.\n",
    "Realizamos o Label Encoding dos IDs e salvamos os metadados (total de usu√°rios/itens) para configurar a arquitetura da rede neural posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f84cee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ 4. Codificando IDs (Label Encoding)...\n",
      "üíæ Salvando Dataset de Treino pronto: data/training_dataset.parquet\n",
      "‚úÖ Conclu√≠do! Metadados: {'num_users': 14761, 'num_items': 8451}\n"
     ]
    }
   ],
   "source": [
    "# Encode de IDs para Inteiros (Necess√°rio para Embeddings do PyTorch)\n",
    "# Em produ√ß√£o, salvar√≠amos esses encoders como artefatos (Pickle/JSON)\n",
    "print(\"üî¢ 4. Codificando IDs (Label Encoding)...\")\n",
    "training_df['user_index'] = training_df['customer_id'].astype('category').cat.codes\n",
    "training_df['item_index'] = training_df['article_id'].astype('category').cat.codes\n",
    "\n",
    "print(f\"üíæ Salvando Dataset de Treino pronto: {TRAIN_DATA_PATH}\")\n",
    "training_df.to_parquet(TRAIN_DATA_PATH)\n",
    "\n",
    "# Salvar metadados para o modelo saber o tamanho dos embeddings\n",
    "meta = {\n",
    "    'num_users': int(training_df['user_index'].max() + 1),\n",
    "    'num_items': int(training_df['item_index'].max() + 1)\n",
    "}\n",
    "import json\n",
    "with open(DATA_PATH / \"model_metadata.json\", \"w\") as f:\n",
    "    json.dump(meta, f)\n",
    "\n",
    "print(\"‚úÖ Conclu√≠do! Metadados:\", meta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
