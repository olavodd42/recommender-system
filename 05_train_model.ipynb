{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57fa2353",
   "metadata": {},
   "source": [
    "# Treinamento do Modelo Two-Tower (Retrieval)\n",
    "Neste notebook, definimos e treinamos nossa rede neural de arquitetura **Two-Tower**.\n",
    "Esta arquitetura Ã© padrÃ£o da indÃºstria para a etapa de *Retrieval* (GeraÃ§Ã£o de Candidatos), pois permite indexar os vetores de itens e realizar buscas ultra-rÃ¡pidas (ANN) em tempo real.\n",
    "\n",
    "## 1. DefiniÃ§Ã£o do Dataset e Modelo\n",
    "\n",
    "### Dataset (`RecSysDataset`)\n",
    "Carrega os dados de treino e prepara os tensores para o PyTorch.\n",
    "\n",
    "### Arquitetura Two-Tower (`TwoTowerModel`)\n",
    "O modelo consiste em duas redes neurais separadas (torres):\n",
    "1.  **User Tower**: Recebe ID do usuÃ¡rio + Features de contexto -> Gera vetor de usuÃ¡rio (Query).\n",
    "2.  **Item Tower**: Recebe ID do item + Features do item -> Gera vetor de item (Candidate).\n",
    "\n",
    "**Loss Function**: Utilizamos **In-Batch Negatives**. Para cada par positivo (usuÃ¡rio, item) no batch, consideramos todos os outros itens do mesmo batch como exemplos negativos. Isso Ã© eficiente e evita a necessidade de amostragem negativa manual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698fc22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "import json\n",
    "import sys\n",
    "\n",
    "sys.path.append('./src')\n",
    "\n",
    "from dataset import RecSysDataset\n",
    "from model import TwoTowerModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c5b220",
   "metadata": {},
   "source": [
    "## 2. ConfiguraÃ§Ã£o do Treinamento\n",
    "Carregamos os metadados (nÃºmero total de usuÃ¡rios e itens) para inicializar as camadas de Embedding com o tamanho correto.\n",
    "Preparamos o `DataLoader` para fornecer batches de dados para a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07955b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Iniciando Treino Two-Tower. Users: 14761, Items: 8451\n",
      "TwoTowerModel(\n",
      "  (user_embedding): Embedding(14761, 32)\n",
      "  (user_mlp): Sequential(\n",
      "    (0): Linear(in_features=34, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  )\n",
      "  (item_embedding): Embedding(8451, 32)\n",
      "  (item_mlp): Sequential(\n",
      "    (0): Linear(in_features=34, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "with open(\"./data/model_metadata.json\", \"r\") as f:\n",
    "    meta = json.load(f)\n",
    "    \n",
    "print(f\"ðŸš€ Iniciando Treino Two-Tower. Users: {meta['num_users']}, Items: {meta['num_items']}\")\n",
    "\n",
    "dataset = RecSysDataset(\"./data/training_dataset.parquet\")\n",
    "dataloader = DataLoader(dataset, batch_size=1024, shuffle=True, num_workers=4)\n",
    "\n",
    "model = TwoTowerModel(num_users=meta['num_users'], num_items=meta['num_items'])\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c540ba",
   "metadata": {},
   "source": [
    "## 3. ExecuÃ§Ã£o do Treinamento\n",
    "Utilizamos o **PyTorch Lightning** para gerenciar o loop de treinamento.\n",
    "Treinamos por 5 Ã©pocas e salvamos o checkpoint do modelo treinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "999d98b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type       | Params | Mode  | FLOPs\n",
      "--------------------------------------------------------------\n",
      "0 | user_embedding | Embedding  | 472 K  | train | 0    \n",
      "1 | user_mlp       | Sequential | 4.3 K  | train | 0    \n",
      "2 | item_embedding | Embedding  | 270 K  | train | 0    \n",
      "3 | item_mlp       | Sequential | 4.3 K  | train | 0    \n",
      "--------------------------------------------------------------\n",
      "751 K     Trainable params\n",
      "0         Non-trainable params\n",
      "751 K     Total params\n",
      "3.006     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "0         Total Flops\n",
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:317: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00, 13.21it/s, v_num=0, train_loss=6.050]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  9.12it/s, v_num=0, train_loss=6.050]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`weights_only` was not set, defaulting to `False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Modelo Treinado! Salvando artefatos...\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=5, accelerator=\"gpu\", devices=1)\n",
    "trainer.fit(model, dataloader)\n",
    "\n",
    "print(\"âœ… Modelo Treinado! Salvando artefatos...\")\n",
    "trainer.save_checkpoint(\"./data/two_tower_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144152eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
