{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ae0b2b0",
   "metadata": {},
   "source": [
    "# Indexa√ß√£o de Vetores no Qdrant\n",
    "Neste notebook, realizamos a indexa√ß√£o dos vetores (embeddings) dos itens no banco de dados vetorial **Qdrant**.\n",
    "Utilizamos a \"Torre de Itens\" do nosso modelo Two-Tower treinado para gerar os vetores de todos os itens do cat√°logo.\n",
    "Isso permitir√° realizar buscas por similaridade (Retrieval) de forma eficiente em tempo real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e2205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "sys.path.append('./src')\n",
    "\n",
    "from model import TwoTowerModel\n",
    "\n",
    "# Configs\n",
    "MODEL_PATH = \"./data/two_tower_model.ckpt\"\n",
    "METADATA_PATH = \"./data/model_metadata.json\"\n",
    "ITEM_FEATURES_PATH = \"./feature_repo/data/item_features.parquet\"\n",
    "QDRANT_HOST = \"qdrant\" # Nome do container no docker network\n",
    "COLLECTION_NAME = \"hm_items\"\n",
    "\n",
    "print(\"üöÄ Iniciando Indexa√ß√£o no Qdrant...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bd4c03",
   "metadata": {},
   "source": [
    "## 1. Carregamento do Modelo Treinado\n",
    "Carregamos o modelo Two-Tower salvo anteriormente (`.ckpt`).\n",
    "Colocamos o modelo em modo de avalia√ß√£o (`eval()`) e congelamos os gradientes, pois usaremos apenas para infer√™ncia (gera√ß√£o de embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54b86a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Carregar Modelo\n",
    "print(\"üß† Carregando modelo treinado...\")\n",
    "model = TwoTowerModel.load_from_checkpoint(MODEL_PATH)\n",
    "model.eval() # Modo de infer√™ncia\n",
    "model.freeze() # Desativar gradientes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b16cadb",
   "metadata": {},
   "source": [
    "## 2. Prepara√ß√£o do Cat√°logo de Itens\n",
    "Carregamos os dados dos itens que ser√£o indexados.\n",
    "Precisamos garantir que temos as mesmas features usadas no treinamento (`popularity_score`, `avg_price`) e os IDs mapeados corretamente (`item_index`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164ca152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Carregar Dados dos Itens (Para ter as features de input)\n",
    "# Precisamos do item_index que criamos no passo 04. \n",
    "# Como o passo 04 salvou o dataset de treino com os indices, vamos pegar de l√° os unicos.\n",
    "print(\"üì¶ Carregando cat√°logo de itens...\")\n",
    "df_train = pd.read_parquet(\"./data/training_dataset.parquet\", columns=[\"item_index\", \"item_id\", \"popularity_score\", \"avg_price\"])\n",
    "# Remover duplicatas para ter apenas itens √∫nicos\n",
    "unique_items = df_train.drop_duplicates(subset=[\"item_index\"]).sort_values(\"item_index\")\n",
    "\n",
    "print(f\"Total de itens √∫nicos a indexar: {len(unique_items)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68bbace",
   "metadata": {},
   "source": [
    "## 3. Configura√ß√£o do Qdrant\n",
    "Conectamos ao servi√ßo do Qdrant e recriamos a cole√ß√£o.\n",
    "Definimos a m√©trica de dist√¢ncia como **Cosseno**, que √© compat√≠vel com a normaliza√ß√£o L2 que aplicamos na sa√≠da do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0a70b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Conectar ao Qdrant\n",
    "client = QdrantClient(host=QDRANT_HOST, port=6333)\n",
    "\n",
    "# Recriar cole√ß√£o (apaga anterior se existir)\n",
    "client.recreate_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config=models.VectorParams(size=32, distance=models.Distance.COSINE),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1139c249",
   "metadata": {},
   "source": [
    "## 4. Gera√ß√£o de Embeddings e Indexa√ß√£o\n",
    "Iteramos sobre todos os itens do cat√°logo em batches.\n",
    "Para cada batch:\n",
    "1.  Passamos os dados pela **Item Tower** do modelo para gerar os vetores.\n",
    "2.  Normalizamos os vetores.\n",
    "3.  Enviamos os vetores e metadados (payload) para o Qdrant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366a0c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Gerar Embeddings e Indexar em Batches\n",
    "batch_size = 256\n",
    "total_batches = len(unique_items) // batch_size + 1\n",
    "\n",
    "print(\"‚ö° Gerando vetores e enviando...\")\n",
    "\n",
    "for i in tqdm(range(0, len(unique_items), batch_size)):\n",
    "    batch = unique_items.iloc[i : i + batch_size]\n",
    "    \n",
    "    # Preparar inputs para o PyTorch\n",
    "    item_ids_tensor = torch.LongTensor(batch['item_index'].values)\n",
    "    \n",
    "    # Normalizar features num√©ricas (mesma l√≥gica do treino)\n",
    "    # Aten√ß√£o: Idealmente voc√™ salva os scalers do treino (min/max) para usar aqui.\n",
    "    # Vou assumir uso direto por simplifica√ß√£o, mas em prod use Scikit-Learn pipelines.\n",
    "    item_feats_tensor = torch.FloatTensor(batch[['popularity_score', 'avg_price']].values)\n",
    "    \n",
    "    # Passar pela ITEM TOWER\n",
    "    with torch.no_grad():\n",
    "        # Acessar apenas a sub-rede de itens\n",
    "        # Precisamos replicar a l√≥gica do forward da torre de itens\n",
    "        i_emb = model.item_embedding(item_ids_tensor)\n",
    "        i_input = torch.cat([i_emb, item_feats_tensor], dim=1)\n",
    "        item_vectors = model.item_mlp(i_input)\n",
    "        # Normalizar L2\n",
    "        item_vectors = torch.nn.functional.normalize(item_vectors, p=2, dim=1)\n",
    "    \n",
    "    # Converter para lista Python\n",
    "    vectors_list = item_vectors.numpy().tolist()\n",
    "    \n",
    "    # Preparar Payloads (Metadados para filtrar depois: Pre√ßo, Categoria, ID original)\n",
    "    # Usamos json.loads(to_json) para garantir tipos nativos e chaves string (evita erro de tipagem)\n",
    "    payloads = json.loads(batch.to_json(orient=\"records\"))\n",
    "    \n",
    "    # IDs no Qdrant (usaremos o item_index como ID num√©rico do ponto)\n",
    "    ids = batch['item_index'].tolist()\n",
    "    \n",
    "    # Upload\n",
    "    client.upsert(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        points=models.Batch(\n",
    "            ids=ids,\n",
    "            vectors=vectors_list,\n",
    "            payloads=payloads\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(f\"‚úÖ Indexa√ß√£o conclu√≠da! Cole√ß√£o '{COLLECTION_NAME}' pronta com {client.count(COLLECTION_NAME).count} vetores.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
